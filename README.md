# 3Ô∏è‚É£ PROJET: TPs-Machine-learning

## üìã Informations Actuelles
- **Lien**: https://github.com/taibi1995/TPs-Machine-learning
- **Type**: Travaux Pratiques / Education
- **Langage**: Python (100%)
- **Fichiers**: 9 fichiers (TD1-TD9)

## ‚ö†Ô∏è Probl√®mes Identifi√©s
1. **README vide ou minimal**
2. **Pas de requirements.txt**
3. **Pas de .gitignore**
4. **Pas de description**
5. **Pas de topics**
6. **Pas de documentation**

---

## üìù Fichiers √† Cr√©er/Modifier

### 1Ô∏è‚É£ README.md (√Ä cr√©er/remplacer)

```markdown
# Travaux Pratiques - Machine Learning ü§ñ

## üìö Description
Collection de travaux pratiques couvrant les concepts et techniques fondamentales du Machine Learning, avec des impl√©mentations pratiques et des cas d'usage r√©els.

## üéØ Objectifs
- Ma√Ætriser les algorithmes de Machine Learning classiques
- Comprendre le preprocessing et la feature engineering
- Impl√©menter la validation crois√©e et l'√©valuation de mod√®les
- R√©soudre des probl√®mes de classification et r√©gression
- D√©velopper l'intuition ML √† travers la pratique

## üìã Liste des Travaux Pratiques

| TD | Sujet | Algorithmes/Concepts |
|----|-------|---------------------|
| **TD1** | Preprocessing | Normalisation, encoding, handling missing values |
| **TD2** | R√©gression Lin√©aire | Linear Regression, Gradient Descent |
| **TD3** | R√©gression Logistique | Binary Classification, Logistic Regression |
| **TD4** | [√Ä compl√©ter] | [√Ä compl√©ter] |
| **TD5** | Classification | Decision Trees, Feature Selection |
| **TD6** | Ensemble Methods | Random Forest, Bagging, Boosting |
| **TD7** | SVM | Support Vector Machines, Kernel Methods |
| **TD8** | Clustering | K-Means, Hierarchical Clustering, DBSCAN |
| **TD9** | Unsupervised Learning | PCA, Dimensionality Reduction |

## üõ†Ô∏è Technologies

- **Python 3.8+**
- **Scikit-learn** - Algorithms ML
- **Pandas** - Data manipulation
- **NumPy** - Numerical computing
- **Matplotlib / Seaborn** - Visualizations
- **Jupyter Notebook** - Interactive development

## üì• Installation

```bash
# Cloner le repository
git clone https://github.com/taibi1995/TPs-Machine-learning.git
cd TPs-Machine-learning

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

## üìñ Utilisation

### Ex√©cuter un TP sp√©cifique

```bash
python TD1.py
python td2.py
python td3.py
# etc...
```

### Utiliser Jupyter Notebook

```bash
# Lancer Jupyter
jupyter notebook

# Ouvrir le fichier souhait√©
```

## üìÇ Structure du Projet

```
.
‚îú‚îÄ‚îÄ TD1.py                  # Preprocessing et Data Cleaning
‚îú‚îÄ‚îÄ td2.py                  # R√©gression Lin√©aire
‚îú‚îÄ‚îÄ td3.py                  # R√©gression Logistique
‚îú‚îÄ‚îÄ td4.py                  # [√Ä d√©crire]
‚îú‚îÄ‚îÄ TD5.py                  # Classification
‚îú‚îÄ‚îÄ td6.py                  # Ensemble Methods
‚îú‚îÄ‚îÄ TD7.py                  # Support Vector Machines
‚îú‚îÄ‚îÄ TD8.py                  # Clustering
‚îú‚îÄ‚îÄ td9.py                  # Unsupervised Learning / PCA
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances
‚îú‚îÄ‚îÄ .gitignore             # Fichiers √† ignorer
‚îî‚îÄ‚îÄ README.md              # Ce fichier
```

## üöÄ Ex√©cution Rapide

```bash
# Ex√©cuter tous les TDs
for file in *.py; do echo "=== $file ===" && python "$file"; done

# Ou un par un
python TD1.py && python td2.py && python td3.py
```

## üìä Concepts Cl√©s Couverts

### Supervised Learning
- **Regression**: Pr√©dire des valeurs continues
- **Classification**: Pr√©dire des cat√©gories

### Unsupervised Learning
- **Clustering**: Regrouper les donn√©es similaires
- **Dimensionality Reduction**: R√©duire le nombre de features

### Model Evaluation
- **Train/Test Split**
- **Cross-Validation**
- **M√©triques**: Accuracy, Precision, Recall, F1-Score
- **Confusion Matrix**

### Feature Engineering
- **Scaling et Normalization**
- **Encoding (One-hot, Label Encoding)**
- **Feature Selection**
- **Handling Imbalanced Data**

## üí° Best Practices

‚úÖ **√Ä FAIRE**:
- Toujours normaliser vos features
- Utiliser la validation crois√©e
- √âvaluer sur un test set ind√©pendant
- Documenter vos exp√©riences
- Comparer plusieurs mod√®les

‚ùå **√Ä √âVITER**:
- Data leakage (fit sur tout le dataset)
- Overfitting (mod√®le trop complexe)
- Ignorer l'imbalance des donn√©es
- Choisir un mod√®le sans justification

## üìö Ressources Recommand√©es

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Pandas Documentation](https://pandas.pydata.org/)
- [Andrew Ng - Machine Learning Course](https://www.coursera.org/learn/machine-learning)
- [StatQuest with Josh Starmer](https://www.youtube.com/@statquest)
- [Hands-On Machine Learning Book](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)

## üîç Conseils pour D√©boguer

```python
# V√©rifier la shape des donn√©es
print(X.shape, y.shape)

# Chercher les valeurs manquantes
print(df.isnull().sum())

# V√©rifier la distribution des classes
print(y.value_counts())

# Tester d'abord sur un petit subset
X_sample = X[:100]
y_sample = y[:100]
```

## üìä Exemple d'Utilisation Compl√®te

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Charger les donn√©es
data = pd.read_csv('data.csv')

# 2. Pr√©parer les features et la cible
X = data.drop('target', axis=1)
y = data['target']

# 3. Splitter
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 4. Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 5. Entra√Æner
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)

# 6. √âvaluer
y_pred = clf.predict(X_test)
print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

## ‚ùì FAQ

**Q: Quelle est la diff√©rence entre TD et TP?**
- **TD**: Travaux Dirig√©s (exercices guid√©s)
- **TP**: Travaux Pratiques (impl√©mentations)

**Q: Comment choisir entre plusieurs mod√®les?**
- Comparez les performances sur le test set
- Utilisez la validation crois√©e pour plus de robustesse
- Consid√©rez la complexit√© et l'interpretabilit√©

## üìù Licence

MIT License

## üë®‚Äçüíª Auteur

**Younes Taibi**
- GitHub: [@taibi1995](https://github.com/taibi1995)

---

**Derni√®re mise √† jour**: F√©vrier 2026
```

### 2Ô∏è‚É£ requirements.txt (√Ä cr√©er)

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
jupyter>=1.0.0
ipython>=7.0.0
scipy>=1.7.0
```

### 3Ô∏è‚É£ .gitignore (√Ä cr√©er)

```
# Jupyter Notebook
.ipynb_checkpoints/
*.ipynb_checkpoints

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/
.venv/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Data files
data/
*.csv
*.xlsx
*.json

# Logs
*.log
```

---

## ‚úÖ Actions √† Effectuer sur GitHub

### 1. Ajouter une description
- Description: "Hands-on practical exercises in Machine Learning covering regression, classification, clustering, and feature engineering using Scikit-learn"

### 2. Ajouter les topics
- `machine-learning`
- `scikit-learn`
- `python`
- `education`
- `supervised-learning`
- `unsupervised-learning`
- `classification`
- `regression`

### 3. Pousser les fichiers
```bash
git add README.md requirements.txt .gitignore
git commit -m "docs: comprehensive ML documentation and dependencies"
git push origin main
```

---

## üìå Suggestions d'Am√©liorations Futures
- Ajouter des datasets exemple pour chaque TD
- Cr√©er des notebooks interactifs
- Ajouter des solutions partielles ou compl√®tes
- Documenter les r√©sultats attendus pour chaque TD
